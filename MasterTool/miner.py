# Dependencies:
# pip install tqdm requests

import warnings
import os

# Suppress all warnings immediately
warnings.filterwarnings("ignore")
os.environ['PYTHONWARNINGS'] = 'ignore'

import csv
import sys
import time
import requests
import json
import random
import string
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from collections import defaultdict

# ==========================================
# ğŸ”§ é…ç½®åŒºåŸŸ
# ==========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SEEDS_FILE = os.path.join(BASE_DIR, 'seeds.txt')
OUTPUT_FILE = os.path.join(BASE_DIR, 'raw_keywords.csv')

MAX_WORKERS = 8
DELAY_MIN = 0.5
DELAY_MAX = 1.0

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

# ==========================================
# ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½
# ==========================================

def contains_chinese(text):
    """æ£€æŸ¥æ˜¯å¦åŒ…å«æ±‰å­—"""
    return bool(re.search(r'[\u4e00-\u9fa5]', text))

def load_seeds():
    if not os.path.exists(SEEDS_FILE): return []
    with open(SEEDS_FILE, 'r', encoding='utf-8') as f:
        seeds = [line.strip() for line in f if line.strip()]
    return seeds

def get_suggestions(url, params, source_name):
    try:
        headers = {'User-Agent': random.choice(USER_AGENTS)}
        time.sleep(random.uniform(DELAY_MIN, DELAY_MAX))
        response = requests.get(url, params=params, headers=headers, timeout=5)
        if response.status_code == 200:
            if source_name == 'Google':
                data = response.json()
                if len(data) > 1: return data[1]
            elif source_name == 'Bing':
                data = response.json()
                if isinstance(data, list) and len(data) > 1: return data[1]
                elif 'SearchSuggestions' in data: return [item['Query'] for item in data['SearchSuggestions']]
    except:
        pass
    return []

def mine_google(query):
    # ä¿æŒå…¨çƒä¸­æ–‡ç¯å¢ƒ
    url = "http://suggestqueries.google.com/complete/search"
    params = {'client': 'chrome', 'q': query, 'hl': 'zh-CN', 'ds': ''}
    return get_suggestions(url, params, 'Google')

def mine_bing(query):
    url = "https://api.bing.com/osjson.aspx"
    params = {'query': query, 'mkt': 'zh-CN'}
    return get_suggestions(url, params, 'Bing')

def mine_single_task(task):
    """
    æ³¨æ„ï¼šè¿™é‡Œä¸å†åšè¿‡æ»¤ï¼Œè€Œæ˜¯å…ˆæŠŠæ‰€æœ‰ä¸œè¥¿éƒ½æŒ–å›æ¥ã€‚
    ç­›é€‰é€»è¾‘æ”¾åˆ°æœ€åç»Ÿä¸€å¤„ç†ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦å¯¹æ¯” Google å’Œ Bing çš„ç»“æœã€‚
    """
    query, seed = task
    results = []
    
    # æŒ– Google
    g_results = mine_google(query)
    for kw in g_results:
        results.append({'kw': kw, 'source': 'Google', 'seed': seed})
        
    # æŒ– Bing
    b_results = mine_bing(query)
    for kw in b_results:
        results.append({'kw': kw, 'source': 'Bing', 'seed': seed})
        
    return results

def get_suffixes():
    suffixes = list(string.ascii_lowercase)
    return suffixes

def main():
    print("ğŸš€ å¯åŠ¨ã€æ™ºèƒ½å…±è¯†ã€‘æŒ–æ˜æ¨¡å¼ (Consensus Mode)...")
    print("ğŸ›¡ï¸  ç­–ç•¥ï¼šä¿ç•™ä¸­æ–‡ OR ä¿ç•™(Google+Bing)å…±åŒæ¨èçš„è‹±æ–‡çƒ­è¯")
    
    seeds = load_seeds()
    if not seeds:
        print("âŒ seeds.txt ä¸ºç©º")
        return

    # 1. ç”Ÿæˆä»»åŠ¡
    suffixes = get_suffixes()
    tasks = []
    for seed in seeds:
        tasks.append((seed, seed))
        for suffix in suffixes:
            tasks.append((f"{seed} {suffix}", seed))
            
    print(f"ğŸ“‹ ä»»åŠ¡æ•°: {len(tasks)}")
    
    # 2. ä¸´æ—¶å­˜å‚¨æ‰€æœ‰æ•°æ® (ç”¨äºå¯¹æ¯”)
    # æ ¼å¼: { "å…³é”®è¯": { "sources": {"Google", "Bing"}, "seed": "xxx" } }
    temp_storage = defaultdict(lambda: {'sources': set(), 'seed': ''})
    
    print("â³ æ­£åœ¨å…¨é¢æŒ–æ˜ (å…ˆé‡‡é›†ï¼Œåæ¸…æ´—)...")
    
    with tqdm(total=len(tasks), desc="Mining", unit="task", ncols=100) as pbar:
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_task = {executor.submit(mine_single_task, task): task for task in tasks}
            
            for future in as_completed(future_to_task):
                try:
                    results = future.result()
                    if results:
                        for item in results:
                            kw = item['kw']
                            src = item['source']
                            # è®°å½•æ•°æ®
                            temp_storage[kw]['sources'].add(src)
                            # è®°å½•æ¥æºç§å­ (ä¿ç•™ç¬¬ä¸€ä¸ªé‡åˆ°çš„å³å¯)
                            if not temp_storage[kw]['seed']:
                                temp_storage[kw]['seed'] = item['seed']
                    pbar.update(1)
                except:
                    pbar.update(1)

    # 3. æ ¸å¿ƒæ¸…æ´—é€»è¾‘ (Smart Filtering)
    print(f"\nğŸ§¹ æ­£åœ¨æ¸…æ´—æ•°æ® (åŸå§‹æ•°æ®é‡: {len(temp_storage)})...")
    final_keywords = []
    
    for kw, data in temp_storage.items():
        sources = data['sources']
        seed = data['seed']
        
        # --- ä½ çš„æ ¸å¿ƒç­–ç•¥ ---
        is_chinese = contains_chinese(kw)
        is_consensus = ('Google' in sources and 'Bing' in sources) # ä¸¤ä¸ªéƒ½æœ‰
        
        should_keep = False
        
        if is_chinese:
            should_keep = True # ä¸­æ–‡ç›´æ¥ç•™
        elif is_consensus:
            should_keep = True # è‹±æ–‡å¦‚æœåŒå¹³å°æ¨èï¼Œè¯´æ˜æ˜¯çƒ­è¯ï¼Œç•™ï¼
        
        if should_keep:
            # å­˜å…¥åˆ—è¡¨ï¼Œå±•å¹³æ¥æº (å¦‚æœä¸¤ä¸ªéƒ½æœ‰ï¼Œå°±å­˜ä¸¤æ¡è®°å½•ï¼Œæ–¹ä¾¿ Analyzer ç»Ÿè®¡çƒ­åº¦)
            for src in sources:
                final_keywords.append([kw, src, seed])

    print(f"âœ¨ æ¸…æ´—å®Œæˆï¼ä¿ç•™äº† {len(final_keywords)} æ¡ã€é«˜ä»·å€¼ã€‘æ•°æ®")
    print(f"ğŸ—‘ï¸  ä¸¢å¼ƒäº† {len(temp_storage) - len(set(x[0] for x in final_keywords))} æ¡ã€å•å¹³å°è‹±æ–‡å™ªéŸ³ã€‘")

    # 4. ä¿å­˜
    if final_keywords:
        with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Keyword', 'Source', 'Seed'])
            writer.writerows(final_keywords)
        print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    else:
        print("âš ï¸ æœªä¿ç•™ä»»ä½•æ•°æ®")

if __name__ == "__main__":
    main()